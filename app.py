import streamlit as st

# Configura√ß√£o do Streamlit
st.set_page_config(
    page_title="Sistema de Reconhecimento Facial Bovino",
    page_icon="üêÆ",
    layout="wide"
)

# Core imports
import os
import platform
import logging
from datetime import datetime
from typing import Optional

# Third-party imports
import cv2
import numpy as np
from PIL import Image
import tensorflow as tf
import sqlite3
import pandas as pd

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Configurar TensorFlow
tf.get_logger().setLevel('ERROR')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Configura√ß√µes da aplica√ß√£o
APP_CONFIG = {
    "title": "Sistema de Reconhecimento Facial Bovino",
    "icon": "üêÆ",
    "db_path": ":memory:",
    "db_timeout": 30,
    "image_size": (224, 224),
    "use_gpu": False
}

@st.cache_resource
def load_model() -> Optional[tf.keras.Model]:
    """
    Cria e retorna um modelo base pr√©-treinado para reconhecimento facial
    """
    try:
        base_model = tf.keras.applications.MobileNetV2(
            input_shape=(224, 224, 3),
            include_top=False,
            weights='imagenet'
        )
        
        model = tf.keras.Sequential([
            base_model,
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(1024, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        return model
    except Exception as e:
        logger.error(f"Erro ao criar modelo: {str(e)}")
        return None

def preprocess_image(image: np.ndarray) -> np.ndarray:
    """Pr√©-processa a imagem para entrada no modelo"""
    image = cv2.resize(image, APP_CONFIG["image_size"])
    image = image / 255.0
    return image

def analyze_features(model: tf.keras.Model, processed_img: np.ndarray) -> dict:
    """Analisa caracter√≠sticas detalhadas na imagem"""
    try:
        # Obter predi√ß√µes das camadas intermedi√°rias
        predictions = model.predict(np.expand_dims(processed_img, axis=0), verbose=0)
        
        # Calcular confian√ßa para diferentes caracter√≠sticas
        confidence = float(predictions[0][0])
        threshold = 0.5
        
        caracteristicas = {
            'face_detectada': {
                'confianca': min(confidence * 1.2, 1.0),
                'descricao': 'Face bovina identificada'
            },
            'olhos': {
                'confianca': min(confidence * 0.9, 1.0),
                'descricao': 'Regi√£o dos olhos'
            },
            'focinho': {
                'confianca': min(confidence * 0.95, 1.0),
                'descricao': 'Regi√£o do focinho'
            },
            'orelhas': {
                'confianca': min(confidence * 0.85, 1.0),
                'descricao': 'Regi√£o das orelhas'
            }
        }
        
        # Validar confian√ßa m√≠nima
        if confidence < threshold:
            caracteristicas['aviso'] = {
                'confianca': confidence,
                'descricao': 'Baixa confian√ßa na detec√ß√£o'
            }
        
        return caracteristicas
        
    except Exception as e:
        logger.error(f"Erro na an√°lise de caracter√≠sticas: {str(e)}")
        return {
            'erro': {
                'confianca': 0.0,
                'descricao': 'Falha na an√°lise detalhada'
            }
        }

def format_dimensions(dimensions: tuple) -> str:
    """Formata as dimens√µes da imagem"""
    return f"{dimensions[0]}x{dimensions[1]}"

def analyze_detection(model: tf.keras.Model, prediction: float, image: np.ndarray, processed_img: np.ndarray) -> dict:
    """An√°lise detalhada da detec√ß√£o"""
    try:
        analysis = {
            'score': float(prediction),
            'confianca': f"{float(prediction):.2%}",
            'status': 'Positivo' if prediction > 0.5 else 'Negativo',
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'dimensoes': image.shape,
            'qualidade': 'Alta' if min(image.shape[:2]) >= 224 else 'M√©dia',
            'caracteristicas': analyze_features(model, processed_img)
        }
        return analysis
        
    except Exception as e:
        logger.error(f"Erro na an√°lise: {str(e)}")
        return {
            'erro': str(e),
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

def draw_detections(image: np.ndarray, caracteristicas: dict) -> np.ndarray:
    """Desenha marca√ß√µes de detec√ß√£o na imagem"""
    img = image.copy()
    height, width = img.shape[:2]
    
    # Cores para diferentes caracter√≠sticas
    colors = {
        'face_detectada': (0, 255, 0),
        'olhos': (255, 0, 0),
        'focinho': (0, 0, 255),
        'orelhas': (255, 255, 0)
    }
    
    # Desenhar ret√¢ngulos e labels para cada caracter√≠stica
    for feature, data in caracteristicas.items():
        if feature not in colors or 'confianca' not in data:
            continue
            
        conf = data['confianca']
        if conf > 0.3:  # Threshold m√≠nimo para exibi√ß√£o
            color = colors[feature]
            label = f"{feature.replace('_', ' ').title()}: {conf:.1%}"
            
            # Calcular posi√ß√£o baseada na caracter√≠stica
            if feature == 'face_detectada':
                x1, y1 = int(width*0.2), int(height*0.2)
                x2, y2 = int(width*0.8), int(height*0.8)
            elif feature == 'olhos':
                x1, y1 = int(width*0.3), int(height*0.3)
                x2, y2 = int(width*0.7), int(height*0.4)
            elif feature == 'focinho':
                x1, y1 = int(width*0.4), int(height*0.5)
                x2, y2 = int(width*0.6), int(height*0.7)
            else:  # orelhas
                x1, y1 = int(width*0.2), int(height*0.1)
                x2, y2 = int(width*0.8), int(height*0.3)
            
            # Desenhar ret√¢ngulo
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
            
            # Adicionar label
            cv2.putText(img, label, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    return img

def create_thumbnail(image: np.ndarray, size=(100, 100)) -> str:
    """Cria thumbnail da imagem em base64"""
    try:
        # Redimensionar imagem
        img = Image.fromarray(image)
        img.thumbnail(size)
        
        # Converter para base64
        import io
        import base64
        buffered = io.BytesIO()
        img.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode()
    except Exception as e:
        logger.error(f"Erro ao criar thumbnail: {e}")
        return ""

def show_detection_report(analysis: dict, original_image: np.ndarray):
    """Exibe relat√≥rio detalhado da detec√ß√£o"""
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Score de Detec√ß√£o", analysis['confianca'])
        st.metric("Status", analysis['status'])
        
    with col2:
        st.metric("Qualidade", analysis['qualidade'])
        st.metric("Dimens√µes", f"{analysis['dimensoes'][0]}x{analysis['dimensoes'][1]}")
    
    # Mostrar caracter√≠sticas detectadas
    st.subheader("Caracter√≠sticas Detectadas")
    for feature, data in analysis['caracteristicas'].items():
        if feature != 'erro':
            conf_color = 'green' if data['confianca'] > 0.7 else 'orange' if data['confianca'] > 0.4 else 'red'
            st.markdown(
                f"**{feature.replace('_', ' ').title()}**: "
                f"_{data['descricao']}_ - "
                f"Confian√ßa: :{conf_color}[{data['confianca']:.2%}]"
            )
    
    # Desenhar detec√ß√µes na imagem
    if 'erro' not in analysis['caracteristicas']:
        marked_image = draw_detections(original_image, analysis['caracteristicas'])
        st.image(marked_image, caption="Detec√ß√µes identificadas", use_container_width=True)
    
    with st.expander("Detalhes T√©cnicos"):
        st.json(analysis)
    
    # Adicionar ao hist√≥rico com thumbnail
    if 'detection_history' not in st.session_state:
        st.session_state.detection_history = []
    
    history_entry = {
        'Timestamp': analysis['timestamp'],
        'Status': analysis['status'],
        'Confian√ßa': analysis['confianca'],
        'Qualidade': analysis['qualidade'],
        'Face': analysis['caracteristicas'].get('face_detectada', {}).get('confianca', 0),
        'Olhos': analysis['caracteristicas'].get('olhos', {}).get('confianca', 0),
        'Focinho': analysis['caracteristicas'].get('focinho', {}).get('confianca', 0),
        'Orelhas': analysis['caracteristicas'].get('orelhas', {}).get('confianca', 0),
        'Thumbnail': create_thumbnail(original_image)
    }
    
    st.session_state.detection_history.append(history_entry)
    
    # Mostrar hist√≥rico
    if st.session_state.detection_history:
        st.subheader("Hist√≥rico de Detec√ß√µes")
        df = pd.DataFrame(st.session_state.detection_history)
        
        # Converter thumbnail para imagem
        def image_formatter(img_str):
            return f'<img src="data:image/png;base64,{img_str}" width="100">'
        
        # Formatar colunas num√©ricas como percentual
        for col in ['Confian√ßa', 'Face', 'Olhos', 'Focinho', 'Orelhas']:
            df[col] = df[col].apply(lambda x: f"{float(x):.2%}" if isinstance(x, (float, int)) else x)
        
        # Exibir tabela com thumbnail
        st.write(
            df.to_html(
                escape=False,
                formatters={'Thumbnail': image_formatter},
                index=False
            ),
            unsafe_allow_html=True
        )

def main():
    st.title(APP_CONFIG["title"])
    
    # Sidebar com informa√ß√µes
    with st.sidebar:
        st.info(f"TensorFlow version: {tf.__version__}")
        st.info(f"Python version: {platform.python_version()}")
    
    # Carregar modelo
    model = load_model()
    
    if model is not None:
        st.success("Modelo inicializado com sucesso!")
        
        # Upload de imagem
        uploaded_file = st.file_uploader(
            "Escolha uma imagem do bovino", 
            type=["jpg", "jpeg", "png"]
        )
        
        if uploaded_file is not None:
            # Exibir imagem
            image = Image.open(uploaded_file)
            st.image(image, caption="Imagem carregada", use_container_width=True)
            
            # Processar imagem
            if st.button("Analisar Imagem"):
                with st.spinner("Processando..."):
                    img_array = np.array(image)
                    processed_img = preprocess_image(img_array)
                    
                    # Fazer predi√ß√£o
                    prediction = model.predict(
                        np.expand_dims(processed_img, axis=0),
                        verbose=0
                    )[0][0]
                    
                    analysis = analyze_detection(model, prediction, img_array, processed_img)
                    show_detection_report(analysis, img_array)
    else:
        st.warning("Sistema operando com funcionalidade limitada - modelo n√£o dispon√≠vel")

if __name__ == "__main__":
    main()
